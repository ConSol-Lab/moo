@InProceedings{10.1007/978-3-031-26409-2_13,
author="Vos, Dani{\"e}l
and Verwer, Sicco",
editor="Amini, Massih-Reza
and Canu, St{\'e}phane
and Fischer, Asja
and Guns, Tias
and Kralj Novak, Petra
and Tsoumakas, Grigorios",
title="Adversarially Robust Decision Tree Relabeling",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="203--218",
abstract="Decision trees are popular models for their interpretation properties and their success in ensemble models for structured data. However, common decision tree learning algorithms produce models that suffer from adversarial examples. Recent work on robust decision tree learning mitigates this issue by taking adversarial perturbations into account during training. While these methods generate robust shallow trees, their relative quality reduces when training deeper trees due the methods being greedy. In this work we propose robust relabeling, a post-learning procedure that optimally changes the prediction labels of decision tree leaves to maximize adversarial robustness. We show this can be achieved in polynomial time in terms of the number of samples and leaves. Our results on 10 datasets show a significant improvement in adversarial accuracy both for single decision trees and tree ensembles. Decision trees and random forests trained with a state-of-the-art robust learning algorithm also benefited from robust relabeling.",
isbn="978-3-031-26409-2",
  html="https://link.springer.com/chapter/10.1007/978-3-031-26409-2_13"
}


@article{Vos_Verwer_2022,
  title={Robust Optimal Classification Trees against Adversarial Examples}, volume={36},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/20829},
  html={https://ojs.aaai.org/index.php/AAAI/article/view/20829},
  DOI={10.1609/aaai.v36i8.20829}, abstractNote={Decision trees are a popular choice of explainable model, but just like neural networks, they suffer from adversarial examples. Existing algorithms for fitting decision trees robust against adversarial examples are greedy heuristics and lack approximation guarantees. In this paper we propose ROCT, a collection of methods to train decision trees that are optimally robust against user-specified attack models. We show that the min-max optimization problem that arises in adversarial learning can be solved using a single minimization formulation for decision trees with 0-1 loss. We propose such formulations in Mixed-Integer Linear Programming and Maximum Satisfiability, which widely available solvers can optimize. We also present a method that determines the upper bound on adversarial accuracy for any model using bipartite matching. Our experimental results demonstrate that the existing heuristics achieve close to optimal scores while ROCT achieves state-of-the-art scores.}, number={8}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Vos, DaniÃ«l and Verwer, Sicco}, year={2022}, month={Jun.}, pages={8520-8528} }
